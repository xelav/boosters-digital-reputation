{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from scipy import sparse, stats\n",
    "from scipy.linalg import svd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import (KFold, StratifiedKFold, cross_val_score,\n",
    "                                     cross_validate, train_test_split)\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool\n",
    "from catboost import cv as catboost_cv\n",
    "from scipy import sparse\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'train/'\n",
    "TEST_PATH = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv(TRAIN_PATH + 'X1.csv')\n",
    "X2 = pd.read_csv(TRAIN_PATH + 'X2.csv')\n",
    "X3 = pd.read_csv(TRAIN_PATH + 'X3.csv')\n",
    "\n",
    "Y = pd.read_csv(TRAIN_PATH + 'Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = pd.read_csv(TEST_PATH + 'X1.csv')\n",
    "X2_test = pd.read_csv(TEST_PATH + 'X2.csv')\n",
    "X3_test = pd.read_csv(TEST_PATH + 'X3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_x2(X2, svd=None):\n",
    "    rows, row_pos = np.unique(X2.iloc[:, 0], return_inverse=True)\n",
    "    cols, col_pos = np.unique(X2.iloc[:, 1], return_inverse=True)\n",
    "    print((len(rows), len(cols)))\n",
    "    sparse_matrix = sparse.csr_matrix((len(rows), len(cols)))\n",
    "\n",
    "    sparse_matrix[row_pos, col_pos] = 1\n",
    "\n",
    "    cols_ = sparse_matrix.sum(axis=0)\n",
    "    rows_ = sparse_matrix.sum(axis=1)\n",
    "\n",
    "    minimum_users_per_group = 5\n",
    "    selected_cols = cols_ >= minimum_users_per_group\n",
    "    trimmed_sparse_matrix = sparse_matrix[:, np.squeeze(np.asarray(selected_cols))]\n",
    "\n",
    "    sns.distplot(trimmed_sparse_matrix.sum(axis=0), bins=100)\n",
    "\n",
    "    if svd is None:\n",
    "        svd = TruncatedSVD(n_components=150)\n",
    "        svd.fit(trimmed_sparse_matrix)\n",
    "\n",
    "    components = pd.DataFrame(svd.transform(trimmed_sparse_matrix))\n",
    "    components['id'] = X2.iloc[:, 0].unique()\n",
    "    X2 = components\n",
    "    return X2, svd\n",
    "\n",
    "def get_x2_summed(X2):\n",
    "    rows, row_pos = np.unique(X2.iloc[:, 0], return_inverse=True)\n",
    "    cols, col_pos = np.unique(X2.iloc[:, 1], return_inverse=True)\n",
    "    sparse_matrix = sparse.csr_matrix((len(rows), len(cols)))\n",
    "\n",
    "    sparse_matrix[row_pos, col_pos] = 1\n",
    "\n",
    "    return np.squeeze(np.asarray(sparse_matrix.sum(axis=1)))\n",
    "\n",
    "def validate(estimator, X_train, y_train, random_state=None, n_folds=5):\n",
    "\n",
    "    cv = KFold(n_splits=n_folds, shuffle=False, random_state=random_state)\n",
    "    cv_iter = list(cv.split(X_train, y_train))\n",
    "\n",
    "    scores=[]\n",
    "    for train, test in tqdm(cv_iter):\n",
    "        estimator.fit(X_train[train, :], y_train[train],\n",
    "                        # eval_set=(X_train[test, :], y_train[test])\n",
    "                        )\n",
    "        pred_statement = estimator.predict_proba(X_train[test, :])[:, 1]\n",
    "        metric = roc_auc_score(y_train[test], pred_statement)\n",
    "        # print(metric)\n",
    "        scores.append(metric)\n",
    "    return np.array(scores)\n",
    "\n",
    "def make_predictions(estimator, exp_name, X_train, Y_train, X_test):\n",
    "    probas = []\n",
    "\n",
    "    for i in tqdm('12345'):\n",
    "\n",
    "        # X_train = X1.merge(Y, on='id', suffixes=('', '_y'),).iloc[:, :-5].drop('id', axis=1).values\n",
    "        y = Y_train[i].values\n",
    "\n",
    "        estimator.fit(X_train, y)\n",
    "        proba = estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        probas.append(proba)\n",
    "\n",
    "    tmp = pd.DataFrame(probas).T\n",
    "    baseline = pd.DataFrame(tmp.values, columns=['1', '2', '3', '4', '5'])\n",
    "    baseline['id'] = X1_test['id']\n",
    "    baseline[['id', '1', '2', '3', '4', '5']].to_csv(exp_name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X3_denormalized(X3):\n",
    "    \n",
    "    return X3\\\n",
    "        .drop('id', axis=1)\\\n",
    "        .multiply(1 / X3[X3 != 0]\\\n",
    "        .min(axis=1), axis=0)\n",
    "\n",
    "# X3_train_summed = X3\\\n",
    "#     .drop('id', axis=1)\\\n",
    "#     .multiply(1 / X3[X3 != 0]\\\n",
    "#     .drop('id', axis=1)\\\n",
    "#     .min(axis=1), axis=0)\\\n",
    "#     .sum(axis=1)\n",
    "# X3_test_summed = X3_test\\\n",
    "#     .drop('id', axis=1).multiply(1 / X3_test[X3_test != 0].drop('id', axis=1).min(axis=1), axis=0).sum(axis=1)\n",
    "\n",
    "\n",
    "X3_train_summed = get_X3_denormalized(X3).sum(axis=1)\n",
    "X3_test_summed  = get_X3_denormalized(X3_test).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36\\lib\\site-packages\\ipykernel_launcher.py:32: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n"
     ]
    }
   ],
   "source": [
    "X_train = X1\\\n",
    "    .assign(X2_summed=get_x2_summed(X2))\\\n",
    "    .assign(X3_summed_dernomalized=X3_train_summed)\\\n",
    "    .assign(X3_non_zero_count=(X3.drop('id',axis=1) != 0).sum(axis=1))\\\n",
    "    .assign(X3_mean=X3.drop('id', axis=1).mean(axis=1))\\\n",
    "    .merge(Y, on='id', suffixes=('', '_y'),)\\\n",
    "    .iloc[:, :-5]\n",
    "\n",
    "X_test = X1_test\\\n",
    "    .assign(X2_summed=get_x2_summed(X2_test))\\\n",
    "    .assign(X3_summed_dernomalized=X3_test_summed)\\\n",
    "    .assign(X3_non_zero_count=(X3_test.drop('id',axis=1) != 0).sum(axis=1))\\\n",
    "    .assign(X3_mean=X3_test.drop('id', axis=1).mean(axis=1))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [00:08<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58371091 0.62171739 0.58833971 0.60352552 0.60595521]\n",
      "0.6006497474402898\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'objective': 'binary:logistic', \n",
    "        'eval_metric': 'auc',\n",
    "        'eta': 0.001,\n",
    "        'max_depth': 1, \n",
    "        'subsample': 0.6, \n",
    "        'colsample_bytree': 0.6,\n",
    "        'alpha':0.001,\n",
    "        # 'random_state': 42, \n",
    "        'silent': True}\n",
    "\n",
    "xgb_cls = xgb.XGBClassifier(n_jobs=8, **xgb_params)\n",
    "\n",
    "scores = validate(xgb_cls, X_train.values, y_train.values)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]Warning: less than 75% gpu memory available for training. Free: 1210.886719 Total: 2048\n",
      " 20%|████████▊                                   | 1/5 [00:28<01:53, 28.45s/it]Warning: less than 75% gpu memory available for training. Free: 1213.878906 Total: 2048\n",
      " 40%|█████████████████▌                          | 2/5 [01:17<01:43, 34.50s/it]Warning: less than 75% gpu memory available for training. Free: 1189.039063 Total: 2048\n",
      " 60%|██████████████████████████▍                 | 3/5 [02:24<01:28, 44.27s/it]Warning: less than 75% gpu memory available for training. Free: 1222.796875 Total: 2048\n",
      " 80%|███████████████████████████████████▏        | 4/5 [03:23<00:48, 48.84s/it]Warning: less than 75% gpu memory available for training. Free: 1248.691406 Total: 2048\n",
      "100%|████████████████████████████████████████████| 5/5 [04:15<00:00, 49.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57121281 0.6185144  0.57983353 0.59744492 0.58199789]\n",
      "0.5898007099871575\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['n_estimators'] = 300\n",
    "params['l2_leaf_reg'] = 30\n",
    "params['learning_rate'] = 0.0005\n",
    "params['depth'] = 1\n",
    "\n",
    "cat_cls = CatBoostClassifier(verbose=False, task_type=\"GPU\", eval_metric=\"AUC\",\n",
    "                         loss_function='CrossEntropy', use_best_model=False, **params)\n",
    "\n",
    "scores = validate(cat_cls, X_train.values, y_train.values)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [02:25<00:00, 37.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59565217 0.60133171 0.58033324 0.61274577 0.61476035]\n",
      "0.6009646495264659\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_cls = lgb.LGBMClassifier(objective='cross_entropy', n_estimators=300, max_depth=5, learning_rate=0.001)\n",
    "\n",
    "scores = validate(lgb_cls, X_train.values, y_train.values)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]Warning: less than 75% gpu memory available for training. Free: 1351.253906 Total: 2048\n",
      " 20%|████████▊                                   | 1/5 [00:46<03:06, 46.53s/it]Warning: less than 75% gpu memory available for training. Free: 1412.339844 Total: 2048\n",
      " 40%|█████████████████▌                          | 2/5 [01:45<02:30, 50.17s/it]Warning: less than 75% gpu memory available for training. Free: 1405.402344 Total: 2048\n",
      " 60%|██████████████████████████▍                 | 3/5 [03:03<01:57, 58.58s/it]Warning: less than 75% gpu memory available for training. Free: 1392.636719 Total: 2048\n",
      " 80%|███████████████████████████████████▏        | 4/5 [05:16<01:20, 80.89s/it]Warning: less than 75% gpu memory available for training. Free: 1478.097656 Total: 2048\n",
      "100%|████████████████████████████████████████████| 5/5 [06:37<00:00, 80.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5908505  0.62379293 0.58937268 0.61400669 0.60951762]\n",
      "0.6055080848951422\n"
     ]
    }
   ],
   "source": [
    "ensemble_cls = VotingClassifier(estimators=[('cat', cat_cls), ('xgb', xgb_cls), ('lgb', lgb_cls)], voting='soft')\n",
    "\n",
    "scores = validate(ensemble_cls, X_train.values, y_train.values)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "make_predictions(ensemble_cls, 'ensemble-X1-X2_sum-with_id-X3-sum-mean-non_zero.csv', X_train, Y, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LB score: 0.588304**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
